\section{Conclusões}
Finalizado este estudo, foi nos possível consolidar o nosso conhecimento relativamente aos algoritmos mais populares usados em \textit{Machine learning}, mais especificamente em processos de classificação multi-classe. 

O foco deste trabalho foi fazer a classificação de textos de \textit{posts} da plataforma \textit{Reddit}. Inicialmente pensávamos que a iniciação deste trabalho fosse mais fácil na medida em que este se trata de um problema de \textit{text classification} e existe muita informação relativa a este tópico. Após algumas tentativas de aplicar os algoritmos mais genéricos de \textit{text classification}, apercebemos-nos que estes não tinham uma boa performance, justificável pela imprevisibilidade dos textos no que toca à formalidade, o que torna a obtenção de \textit{features} mais difícil.

Numa fase inicial o esforço foi todo focado na etapa de pré-processamento dos textos, pois esta é bastante importante para a performance geral do modelo. Nesta etapa é feita a transformação de texto no formato \textit{"raw"} em vectores numéricos capazes de transmitir informações sobre os textos. Num problema deste tipo, a dimensão das \textit{features} de entrada é igual ao tamanho do vocabulário definido para o \textit{corpus} em questão. Logo, devido a isto, foi necessário fazer a segmentação do vocabulário original, pois este atinge dimensões nas ordens dos milhões, o que acaba por ser um número elevado de \textit{features} de entrada do modelo.


Foi possível concluir que especificamente para este \textit{dataset}, o algoritmo que obteve melhor performance foi o de \textit{Logistic Regression}. Contudo, é de ter em atenção que o treino de modelos que usem este algoritmo para uma grande quantidade de \textit{features} e de dados de treino se torna penosamente lento. Por exemplo, para o melhor modelo que obtivemos, o modelo demorou aproximadamente 4 horas a ser treinado, o que em algumas implementações pode não ser o mais aceitável. Sendo assim, os modelos de redes neuronais e de redes de \textit{bayes} apresentados, apesar de não terem tido uma prestação tão boa, podem ter uma utilização mais aceitável em circunstâncias em que o tempo de treino tenha de ser reduzido (estes dois modelos demoraram entre 2 a 3 minutos a serem treinados).

Neste trabalho reforçou-se ainda mais a ideia que a performance de um modelo de \textit{machine learning} está muito relacionada com a qualidade e processamento do \textit{dataset}, daí que muita das vezes um esforço inicial seja para regularizar e optimizar o conteúdo do \textit{dataset}, de forma a que o modelo consiga tirar partido da qualidade de selecção de \textit{features} e ecossistema do \textit{dataset}. Este facto provou-se na prática neste trabalho quando, se compara o uso de dois algoritmos (redes de \textit{bayes} deste relatório e rede de bayes de um \textit{paper}) iguais com processamentos de dados diferentes, o esforço colocado nesse aspecto neste trabalho trouxe benefícios na performance geral do modelo.
